import geopandas as gpd
import pandas as pd
import matplotlib.pyplot as plt
from shapely.geometry import Point
# --- 1. Load Earthquake Vulnerability Zones Shapefile ---
path = "../data/bgd_nhr_earthquake_barc"
gdf = gpd.read_file(path)

print("Earthquake Zones CRS:", gdf.crs)
print(gdf.head())

# --- 2. Load Roads CSV and Convert to GeoDataFrame ---
roads_path = "../data/_roads3.csv"
df_roads = pd.read_csv(roads_path)

# Rename if needed for clarity
df_roads = df_roads.rename(columns={"lat": "latitude", "lon": "longitude"})

# Create geometry column from lat/lon
geometry = [Point(xy) for xy in zip(df_roads["longitude"], df_roads["latitude"])]
gdf_roads = gpd.GeoDataFrame(df_roads, geometry=geometry, crs="EPSG:4326")  # WGS 84

# --- 3. Reproject Roads to Match Shapefile CRS ---
gdf_roads = gdf_roads.to_crs(gdf.crs)

# --- 4. Perform Spatial Join ---
joined = gpd.sjoin(gdf_roads, gdf, how="left", predicate="within")

# --- 5. Select Relevant Columns (Optional) ---
relevant_columns = df_roads.columns.tolist() + ['ZONE', 'CO_EFFIC', 'EARTHQUF_I']
result = joined[relevant_columns]

# --- 6. Export or Analyze ---
print(result.head())
result.to_csv("../data/roads_with_earthquake_vulnerability.csv", index=False)

average_score_per_road = result.groupby("road")["EARTHQUF_I"].mean().reset_index()
average_score_per_road = average_score_per_road.rename(columns={"EARTHQUF_I": "avg_earthquake_score"})

# Display the result
print(average_score_per_road)
average_score_per_road.value_counts()

